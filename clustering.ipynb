{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task that is proposed to be completed as part of the homework has a declared \"price\" in points. The maximum possible amount is 10 points, and together with the bonus assignment - 12 points. It is not necessary to complete all the tasks, only a part can be done. Most of the points expect you to write working Python code; sometimes you will need to write comments - for example, to compare several approaches to solve the same problem. Also you can add more cells for your convenience if you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework focuses on clustering. We will work with images of handwritten digits, learn how to cluster them using two different methods (hierarchical clustering and the ùêæ-means algorithm), evaluate the quality of the partition and choose the optimal number of clusters, as well as visualize intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "The data we will be working with is available in the scikit-learn library (`sklearn` module) in the `datasets` submodule via the `load_digits` function. The data contains 1,797 observations, each of which is 8√ó8 pixel image of a handwritten digit from 0 to 9. This is about the same amount of each digit (about 180).\n",
    "\n",
    "For convenience, every image expands to a 64 (8√ó8) row, so entire numpy array is 1797√ó64. The color intensity in each pixel is encoded with an integer from 0 to 16.\n",
    "\n",
    "In addition to images, their labels are also known. In this task, we will assume that the labels (as well as their amount) are unknown and try to group the data in such a way that the resulting clusters 'better match' the original ones. Possible options for determining the 'better match' are presented later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.25 points)** Load the images into `X` variable, and their labels into `y` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == (1797, 64)\n",
    "assert y.shape == (1797,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the first 10 images.\n",
    "\n",
    "- Arrange images on a grid rather than in a row. You may need the `subplot` and `imshow` functions from the `pyplot` module in the `matplotlib` library.\n",
    "- You will also need to reshape the images to 8√ó8.\n",
    "- Remove ticks and labels from both axes. The `xticks` and `yticks` functions or the `tick_params` function from `pyplot` can help you with this.\n",
    "- Make the output good sized with the `figure` function from `pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "cycle = 0\n",
    "for image, label in zip(X[:10], y[:10]):\n",
    "    cycle += 1\n",
    "    subplot = plt.subplot(2, 5, cycle)\n",
    "    plt.xticks(visible=False)\n",
    "    plt.yticks(visible=False)\n",
    "    subplot.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering and quality evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the the KMeans algorithm. Use objective function $L = \\sum_{i=1}^{n}|x_{i}-Z_{A(x_{i})}|^{2}$, where $Z_{A(x_{i})}$ is the center of the cluster corresponding to $x_{i}$ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances = np.zeros((X.shape[0], cluster_centers.shape[0]))\n",
    "# for i in range(X.shape[0]):\n",
    "#     distances[i,:] = np.sqrt(np.sum((X[i] - cluster_centers)**2, axis=1))\n",
    "# return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKMeans:\n",
    "    def __init__(self, n_clusters=2, max_iter=30, n_init=10, random_state=42):\n",
    "        '''K-Means clustering.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters: int, default=2\n",
    "                The number of clusters to be formed is also \n",
    "                the number of centroids to generate. \n",
    "            max_iter: int, default=300\n",
    "                Maximum number of iterations of the k-means algorithm for a\n",
    "                single run.\n",
    "            n_init: int, default=10\n",
    "                Number of time the k-means algorithm will be run with different\n",
    "                centroid seeds. The final results will be the best output of\n",
    "                n_init consecutive runs in terms of objective function.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "        '''\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = RandomState(seed=random_state)\n",
    "        \n",
    "    def calculate_distances_to_centroids(self, X, cluster_centers):\n",
    "        \"\"\"\n",
    "        Returns (n, c) matrix where the element at position (i, j) \n",
    "        is the distance from i-th object to j-th centroid.\"\"\"\n",
    "        return pairwise_distances(X, cluster_centers)\n",
    "    \n",
    "    def update_centroids(self, X, nearest_clusters):\n",
    "        \"\"\"\n",
    "        Returns numpy array of shape (n_clusters, n_features) - \n",
    "        new clusters that are found by averaging objects belonging \n",
    "        to the corresponding cluster.\"\"\"\n",
    "        return np.array([np.mean(X[np.where(nearest_clusters == i)], axis=0) for i in np.unique(nearest_clusters)])  \n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        assert X.shape[0] >= self.n_clusters\n",
    "\n",
    "        self.cluster_centers_ = None\n",
    "        current_l2_norm = 100000000000\n",
    "        for j in range(self.n_init):\n",
    "            row, col = X.shape\n",
    "            cluster_centers = np.zeros((self.n_clusters, X.shape[1]))\n",
    "            for i in range(self.n_clusters):\n",
    "                randIndex = self.random_state.randint(row)\n",
    "                cluster_centers[i] = X[randIndex]\n",
    "\n",
    "            for i in range(self.max_iter):\n",
    "                nearest_clusters = self.calculate_distances_to_centroids(X, cluster_centers)\n",
    "                cluster_centers = self.update_centroids(X, np.argmin(nearest_clusters, axis=0))\n",
    "            previous_l2_norm = current_l2_norm\n",
    "#             current_l2_norm = np.linalg.norm(cluster_centers)**2\n",
    "            nearest_clusters = self.calculate_distances_to_centroids(X, cluster_centers)\n",
    "            current_l2_norm = np.linalg.norm(np.min(nearest_clusters, axis=1)**2)\n",
    "            if current_l2_norm < previous_l2_norm:\n",
    "                self.cluster_centers_ = cluster_centers\n",
    "        return self\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted cluster labels.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'cluster_centers_'):\n",
    "            distances_to_predict = self.calculate_distances_to_centroids(X, self.cluster_centers_)\n",
    "            clusters = np.argmin(distances_to_predict, axis=1)\n",
    "            return clusters\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomKMeans instance is not fitted yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 points)** Get the `X` array partition into 10 clusters. Visualize the centers of clusters.\n",
    "- We will assume that the center of the cluster is average value of all observations belonging to the cluster.\n",
    "- The cluster centers should have the same shape as our observations (64). So you have to average the points across the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 3 ... 6 1 7]\n"
     ]
    }
   ],
   "source": [
    "custom_kmeans = CustomKMeans(n_clusters=10, max_iter=30, n_init=10, random_state=15)\n",
    "custom_kmeans.fit(X)\n",
    "custom_kmeans_labels = custom_kmeans.predict(X)\n",
    "assert custom_kmeans_labels.shape == (1797,)\n",
    "print(custom_kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(2,5,figsize=(16,8))\n",
    "count = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(custom_kmeans.cluster_centers_[count].reshape(8,8))\n",
    "        ax[i, j].axis('off')\n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Experiment with `max_iter` and `n_init` parameters. Look at the range of values of the objective function, it's best values, at what parameters and how often they are achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/1771113304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn_init\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mcustom_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mcustom_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mcustom_kmeans_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/1669405083.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mnearest_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_distances_to_centroids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                 \u001b[0mcluster_centers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_centroids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnearest_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mprevious_l2_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_l2_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/1669405083.py\u001b[0m in \u001b[0;36mcalculate_distances_to_centroids\u001b[1;34m(self, X, cluster_centers)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mthe\u001b[0m \u001b[0melement\u001b[0m \u001b[0mat\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         is the distance from i-th object to j-th centroid.\"\"\"\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_centroids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1889\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    300\u001b[0m            [1.41421356]])\n\u001b[0;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_norm_squared\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         X = check_array(\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"fc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2259\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2260\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for max_iter in range(1, 20):\n",
    "    for n_init in range(1, 20):\n",
    "        custom_kmeans = CustomKMeans(n_clusters=n_init, max_iter=max_iter, n_init=10, random_state=15)\n",
    "        custom_kmeans.fit(X)\n",
    "        custom_kmeans_labels = custom_kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use two popular algorithms: hierarchical clustering and $K$-means clustering. These and other algorithms are available in the `scikit-learn` module in the `cluster` submodule. Hierarchical clustering is called `AgglomerativeClustering`, and the $K$-means method is called `KMeans`.\n",
    "\n",
    "**(0.5 points)** Use each of the two methods: hierarchical clustering and KMeans. Get the `X` array partition into 10 clusters.\n",
    "\n",
    "- Note that `AgglomerativeClustering` does not have a `predict` method, so you can either use the `fit_predict` method or use the `fit` method and then look at the `labels_` attribute of the class instance.\n",
    "- Kmeans performs multiple runs (default 10) with random centers and then returns the best partition in terms of average distance within the clusters. You can increase the number of runs to improve the quality of predictions in the `i_init` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(n_clusters=10).fit(X)\n",
    "hierarchical_labels = clustering.labels_ \n",
    "kmeans = KMeans(n_clusters=10, random_state=15).fit(X)\n",
    "kmeans_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hierarchical_labels.shape == (1797,)\n",
    "assert kmeans_labels.shape == (1797,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the centers of clusters obtained by both methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Hierarchical Clusteing (Agglomerative Clustering)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (64,) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19196/4009398335.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5486\u001b[0m                               **kwargs)\n\u001b[0;32m   5487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5488\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5489\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MiniConda\\envs\\rsschool-machine-learning-course\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    713\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    714\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 715\u001b[1;33m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[0;32m    716\u001b[0m                             .format(self._A.shape))\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (64,) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp=[]\n",
    "for i in set(hierarchical_labels):\n",
    "    x = np.mean(X[np.where(hierarchical_labels == i)], axis=0)\n",
    "    temp.append(list(x))\n",
    "np.arraytemp\n",
    "f, ax = plt.subplots(2,5,figsize=(16,8))\n",
    "count = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(temp[count].reshape(8,8))\n",
    "        ax[i, j].axis('off')\n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_KMeans clustering_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,5,figsize=(16,8))\n",
    "count = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(kmeans.cluster_centers_[count].reshape(8,8))\n",
    "        ax[i, j].axis('off')\n",
    "        count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a situation where the true number of classes is unknown, we can select it by maximazing some metric.\n",
    "\n",
    "When we can set some distance function between our observations, we can consider the `silhouette` distance as a function of measuring the quality of the clustering. Let's show how it is calculated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ ‚Äì set of observations, $M \\subset X$ ‚Äì one of the clusters obtained as a result of clustering process, $\\rho$ ‚Äì some metric on $X$. Let's choose one observation $x \\in M$. Denote $a(x)$ as the average distance from $x$ to  $x'$ points from the same cluster:\n",
    "$$\n",
    "a(x) = \\frac{1}{|M| - 1} \\sum_{x' \\in M,\\, x' \\ne x} \\rho(x,\\, x')\n",
    "$$\n",
    "\n",
    "Denote $b(x)$ as minimun of average distances from $x$ to $x''$ from some other cluster $N$:\n",
    "$$\n",
    "b(x) = \\min_{N \\ne M} \\frac{1}{|N|} \\sum_{x'' \\in N} \\rho(x,\\, x'')\n",
    "$$\n",
    "\n",
    "The silhouette is difference between a(x) and b(x), normalized to $[-1, \\, 1]$ and averaged over all observations:\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\frac{b(x) - a(x)}{\\max(a(x),\\, b(x))}\n",
    "$$\n",
    "\n",
    "The implementation of this metric in the `scikit-learn` is the `silhouette_score` function from the `metrics` submidule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(0.75 point)** For each $K$ between 2 and 20 inclusive, partition of the array $X$ into $K$ clusters using both methods. Calculate the silhouette score and visualize it for both methods on the same plot ($K$ on the $x$ axis and silhouette score on the $y$ axis). Sign the axes and make a legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Calculater the silhouette score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhoutte_score_kmeans = []\n",
    "silhoutte_score_agglomerative_clustering = []\n",
    "for n_clusters in range(2, 21):\n",
    "    #hierarhical clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters).fit(X)\n",
    "    hierarchical_labels = clustering.labels_\n",
    "    silhoutte_score_agglomerative_clustering.append(silhouette_score(X, hierarchical_labels))\n",
    "    \n",
    "    #kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    silhoutte_score_kmeans.append(silhouette_score(X, kmeans_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Plot silhoutter score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4.5))\n",
    "x_axis = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "plt.plot(x_axis, silhoutte_score_kmeans, label='Kmeans')\n",
    "plt.plot(x_axis, silhoutte_score_agglomerative_clustering, color='C1', label='Agglomerative clustering')\n",
    "plt.title('')\n",
    "plt.xlabel('K (n_clusters)')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.legend(loc='center left')               \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we know the true clustering labels, the clustering result can be compared to them using measures such as `homogeneity`, `completeness` and their harmonic mean - $V$-score. The definitions of these quantities are rather bulky and are based on the [entropy of the probability distribution](https://ru.wikipedia.org/wiki/–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è_—ç–Ω—Ç—Ä–æ–ø–∏—è). Details are given in [this article](http://aclweb.org/anthology/D/D07/D07-1043.pdf). In practice, it's enough to know that `homogeneity`, `completeness` and $V$-score are in the range from 0 and 1, and the more, the better.\n",
    "\n",
    "Since we know what digit each image is (`y` array), we can compare the clustering results to it using the measures listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Repeat the previous task using $V$-measure instead of silhouette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Calculate V measure score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "v_measure_score_kmeans = []\n",
    "v_measure_score_agglomerative_clustering = []\n",
    "for n_clusters in range(2, 21):\n",
    "    #hierarhical clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters).fit(X)\n",
    "    hierarchical_labels = clustering.labels_\n",
    "    v_measure_score_agglomerative_clustering.append(v_measure_score(y, hierarchical_labels))\n",
    "    \n",
    "    #kmeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    v_measure_score_kmeans.append(v_measure_score(y, kmeans_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Plot V score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4.5))\n",
    "x_axis = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "plt.plot(x_axis, v_measure_score_kmeans, label='Kmeans')\n",
    "plt.plot(x_axis, v_measure_score_agglomerative_clustering, color='C1', label='Agglomerative clustering')\n",
    "plt.title('')\n",
    "plt.xlabel('K (n_clusters)')\n",
    "plt.ylabel('V score')\n",
    "plt.legend(loc='center left')               \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature space dimensionality reduction\n",
    "\n",
    "In some cases, especially when there are a large number of features, when not all of them are informative, and some of them are correlated, it can be useful to reduce the dimension of the feature space. This mean that instead of $d$ original features, we will go to $d'\\ll d$ new ones. And if earlier our data were presented in the form of an $n√ód$ matrix, then it will presented as a $n√ód'$.\n",
    "\n",
    "There are two popular dimensionality reduction approaches:\n",
    "- select new features from existing features;\n",
    "- extract the new features by transforming old ones, for example, by making $d'$ different linear combinations of columns of an $n√ód$ matrix.\n",
    "\n",
    "One widely used dimensionality reduction technique is the Singular Value Decomposition (SVD). This method allows you to construct any number $d'\\leq d$ of new features in such a way that they are the most informative (in some sense).\n",
    "\n",
    "The `scikit-learn` module has several implementations of singular value decomposition. We will use the `TruncatedSVD` class from the `decomposition` submodule.\n",
    "\n",
    "**Note:** The singular value decomposition of the matrix $M$ is usually written as $M=U \\Sigma V^{*}$. `TruncatedSVD`, in turn, returns only the $d'$ first columns of the matrix $U$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.75 point)** Perform a singular value decomposition of the $X$ matrix, leaving 2, 5, 10, 20 features. In each case, perform hierarchical clustering and $K$-Means clustering (take the number of clusters equal to 10). Calculate the silhouette and $V$-score and compare them to corresponding values obtained from the original data.\n",
    "\n",
    "**Note**: It is not valid to compare the silhouette calculated with different metrics. Even if we use the same metric function when calculating the distance between points in the data, after applying dimensionality reduction or other data transformations, we will (not always) get different silhouette scores. Therefore, after training the clustering algorithm, to compare the result of clustering, you need to calculate the silhouette on the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Perform a singular value decomposition of the  ùëã  matrix, leaving 2, 5, 10, 20 features_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "truncatedSVD = TruncatedSVD(n_components=20)\n",
    "data_with_20_features = truncatedSVD.fit_transform(X)\n",
    "\n",
    "truncatedSVD = TruncatedSVD(n_components=10)\n",
    "data_with_10_features = truncatedSVD.fit_transform(X)\n",
    "\n",
    "truncatedSVD = TruncatedSVD(n_components=5)\n",
    "data_with_5_features = truncatedSVD.fit_transform(X)\n",
    "\n",
    "truncatedSVD = TruncatedSVD(n_components=2)\n",
    "data_with_2_features = truncatedSVD.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_silhouette score and perform hierarchical clustering and  ùêæ -Means clustering (take the number of clusters equal to 10)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "different_amount_of_features = [data_with_2_features, data_with_5_features, data_with_10_features, data_with_20_features]\n",
    "silhouette_score_agglomerative_clustering = []\n",
    "silhouette_score_kmeans = []\n",
    "for the_amount_of_features in different_amount_of_features:\n",
    "    #hierarhical clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=10).fit(the_amount_of_features)\n",
    "    hierarchical_labels = clustering.labels_\n",
    "    silhouette_score_agglomerative_clustering.append(silhouette_score(X, hierarchical_labels))\n",
    "    \n",
    "    #kmeans\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42).fit(the_amount_of_features)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    silhouette_score_kmeans.append(silhouette_score(X, kmeans_labels))\n",
    "print('Kmeans: ', silhouette_score_kmeans)\n",
    "print('Hierarhical clustering: ', silhouette_score_agglomerative_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Original data silhouette score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=10).fit(X)\n",
    "hierarchical_labels = clustering.labels_\n",
    "silhouette_score_agglomerative_clustering_all_features = (silhouette_score(X, hierarchical_labels))\n",
    "\n",
    "#kmeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(X)\n",
    "kmeans_labels = kmeans.labels_\n",
    "silhouette_score_kmeans_all_features = (silhouette_score(X, kmeans_labels))\n",
    "print('Kmeans: ', silhouette_score_kmeans_all_features)\n",
    "print('Hierarhical clustering: ', silhouette_score_agglomerative_clustering_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_V score and perform hierarchical clustering and  ùêæ -Means clustering (take the number of clusters equal to 10)_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "different_amount_of_features = [data_with_2_features, data_with_5_features, data_with_10_features, data_with_20_features]\n",
    "v_measure_score_agglomerative_clustering = []\n",
    "v_measure_score_kmeans = []\n",
    "for the_amount_of_features in different_amount_of_features:\n",
    "    #hierarhical clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=10).fit(the_amount_of_features)\n",
    "    hierarchical_labels = clustering.labels_\n",
    "    v_measure_score_agglomerative_clustering.append(v_measure_score(y, hierarchical_labels))\n",
    "    \n",
    "    #kmeans\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42).fit(the_amount_of_features)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    v_measure_score_kmeans.append(v_measure_score(y, kmeans_labels))\n",
    "print('Kmeans: ', v_measure_score_kmeans)\n",
    "print('Hierarhical clustering: ', v_measure_score_agglomerative_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Original data V score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=10).fit(X)\n",
    "hierarchical_labels = clustering.labels_\n",
    "v_measure_score_agglomerative_clustering_all_features = (v_measure_score(y, hierarchical_labels))\n",
    "\n",
    "#kmeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=42).fit(X)\n",
    "kmeans_labels = kmeans.labels_\n",
    "v_measure_score_kmeans_all_features = (v_measure_score(y, kmeans_labels))\n",
    "print('Kmeans: ', v_measure_score_kmeans_all_features)\n",
    "print('Hierarhical clustering: ', v_measure_score_agglomerative_clustering_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular dimensionality reduction approach that is useful for working with images is t-distributed stochastic neighbor embeddings, abbreviated `tSNE`. Unlike singular value decomposition, this it is non-linear transformation. It's main idea is to map points from a space of dimension `d` to another space of dimension 2 or 3 in such a way that the distances between points are mostly preserved. Mathematical details can be found, for example, [here](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding).\n",
    "\n",
    "The implementation of `tSNE` in the `scikit-learn` library is the `TSNE` class in the `manifold` submodule.\n",
    "\n",
    "**Note:** In recent years [UMAP](https://github.com/lmcinnes/umap) is often used istead of `tSNE`. It is a faster algorithm with similar properties. We don't ask you to use `UMAP` because it requires you to install another dependency, the `umap-learn` library. Those who wish can perform the following task using `UMAP`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Perform a tSNE-transform of the `X` matrix, leaving 2 features. Visualize the obtained data in the form of a scatter plot form: the first feature on the horizontal axis, and the second one the vertical axis. Color the points according to the digits they belong to.\n",
    "\n",
    "- The `c` parameter in the plt.scatter function is responsible for the color of the points. Pass the true labels to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Perform a tSNE-transform of the X matrix, leaving 2 features_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_after_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "X_after_tsne.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Visualize the obtained data in the form of a scatter plot form_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=X[0], y=X[1], c=['red', 'green']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** From the data transformed using the tSNE, perform hierarchical clustering and $K$-means clustering (take the number of clusters equal to 10). Calculate the silhouette and the $V$-score and compare them to corresponding values obtained from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.25 points)** Choose the best partition (in terms of silhouette or $V$-score) and visualize the centers of clusters with images. Did you managed to make each digit correspond to one center of the cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results and bonus part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write in free form what conclusions you made after completing this assignment. Answer the following questions:\n",
    "\n",
    "**(0.5 points)** Which algorithm gives more meaningful results - hierarchical clustering or $K$- means clustering. Does it depend on the algorithm settings or on the quality evaluation method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Imagine the situation where after hierarchical clustering, you need to cluster new data in the same way without retraining the model. Suggest a method how you will do it and how you will measure the quality of clustering of new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**(0.5 points)** Does dimensionality reduction improve clustering results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How to evaluate the quality of dimensional reduction? Suggest at least 2 options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Bonus 2 points)** Load the [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist) dataset. You can also do it with `scikit-learn` as explained [here](https://stackoverflow.com/a/60450028). Explore the data and try to cluster it using different approaches. Compare results of these approaches using the silhouette and the $V$-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
