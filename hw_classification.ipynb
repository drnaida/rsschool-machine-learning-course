{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{2C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, eta=0.001, max_iter=1000, C=1.0, tol=1e-5, random_state=42, zero_init=False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = np.random.RandomState(seed=random_state)\n",
    "        self.zero_init = zero_init\n",
    "         \n",
    "    def get_sigmoid(self, X, weights):\n",
    "        \"\"\"Compute the sigmoid value.\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-np.dot(X, weights)))\n",
    "    \n",
    "    def get_loss(self, x, weights, y):\n",
    "        \"\"\"Calculate the loss.\"\"\"\n",
    "        return sum(log(1 + np.exp(np.dot(weights, x) * y))) / len(y) + ((1 / 2*self.C)*numpy.linalg.norm(weights))\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X]) # a constant feature is included to handle intercept\n",
    "        num_features = X_ext.shape[1]\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features) \n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low=-weight_threshold,\n",
    "                                                      high=weight_threshold, size=num_features) # random weight initialization\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            delta = (self.eta/len(y)) * sum()\n",
    "            self.weights_ -= self.eta * delta\n",
    "            w_t = self.weights + self.eta * delta\n",
    "            if (self.max_iter > self.tol) or (np.linalg.norm(w_t - self.weights_) > self.tol):\n",
    "                break\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        if self.predict_proba(X) > 0.5\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "#y_train = \"<your code>\"\n",
    "#y_test = \"<your code>\"\n",
    "y_train = (y_train % 2) * 2 - 1\n",
    "y_test = (y_test % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(y_pred=clf.predict(X_train), y_true=y_train), \\\n",
    "           metrics.accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter=1, zero_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18728/1338283876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18728/683116459.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"<your code>\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"<your code>\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([ 3.1000e-06,  0.0000e+00,  4.1800e-05,  5.4770e-04,  2.2130e-04,\n",
    "        4.8750e-04,  1.3577e-03,  5.9780e-04,  5.6400e-05, -7.0000e-07,\n",
    "        1.6910e-04,  2.5190e-04, -4.3700e-04,  3.6190e-04,  1.0049e-03,\n",
    "        4.2280e-04,  2.5700e-05,  3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "       -2.6200e-04,  8.7540e-04,  4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "        0.0000e+00, -2.2160e-04, -5.7130e-04,  9.8570e-04,  1.3507e-03,\n",
    "        5.0210e-04, -1.7050e-04, -1.0000e-06,  0.0000e+00, -6.7810e-04,\n",
    "       -1.0515e-03, -4.4500e-05,  3.7160e-04,  4.2100e-04, -8.1800e-05,\n",
    "        0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "        1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "       -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "       -3.9560e-04, -1.7700e-05, -3.0000e-07,  2.6800e-05,  6.3920e-04,\n",
    "        1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min(train_acc, test_acc) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement weighted K-Neighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that training a KNN classifier is simply memorizing a training sample. \n",
    "\n",
    "The process of applying a classifier for one object is to find the distances from it to all objects in the training data, then select the k nearest objects (neighbors) and return the most common class among these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give the nearest neighbors weights in accordance with the distance of the object to them. In the simplest case (as in your assignment), you can set the weights inversely proportional to that distance. \n",
    "\n",
    "$$w_{i} = \\frac{1}{d_{i} + eps},$$\n",
    "\n",
    "where $d_{i}$ is the distance between object and i-th nearest neighbor and $eps$ is the small value to prevent division by zero.\n",
    "\n",
    "In case of 'uniform' weights, all k nearest neighbors are equivalent (have equal weight, for example $w_{i} = 1, \\forall i \\in(1,k)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the probability of classes, it is necessary to normalize the weights of each class, dividing them by the sum:\n",
    "\n",
    "$$p_{i} = \\frac{w_{i}}{\\sum_{j=1}^{c}w_{j}},$$\n",
    "\n",
    "where $p_i$ is probability of i-th class and $c$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits. By implementing this algorithm, you will be able to classify numbers not only into \"even\" or \"odd\", but into their real representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNeighborsClassifier:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, weights='uniform', eps=1e-9):\n",
    "        \"\"\"K-Nearest Neighbors classifier.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: int, default=5\n",
    "                Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "            weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "                Weight function used in prediction.  Possible values:\n",
    "                - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "                  are weighted equally.\n",
    "                - 'distance' : weight points by the inverse of their distance.\n",
    "                  in this case, closer neighbors of a query point will have a\n",
    "                  greater influence than neighbors which are further away.\n",
    "            eps : float, default=1e-5\n",
    "                Epsilon to prevent division by 0 \n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def get_pairwise_distances(self, X, Y):\n",
    "        \"\"\"\n",
    "        Returnes matrix of the pairwise distances between the rows from both X and Y.\n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            Y: numpy array of shape (k_samples, n_features)\n",
    "        Returns:\n",
    "            P: numpy array of shape (n_samples, k_samples)\n",
    "                Matrix in which (i, j) value is the distance \n",
    "                between i'th row from the X and j'th row from the Y.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def get_class_weights(self, y, weights):\n",
    "        \"\"\"\n",
    "        Returns a vector with sum of weights for each class \n",
    "        Args:\n",
    "            y: numpy array of shape (n_samles,)\n",
    "            weights: numpy array of shape (n_samples,)\n",
    "                The weights of the corresponding points of y.\n",
    "        Returns:\n",
    "            p: numpy array of shape (n_classes)\n",
    "                Array where the value at the i-th position \n",
    "                corresponds to the weight of the i-th class.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.points = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples, n_classes)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'points'):\n",
    "            P = self.get_pairwise_distances(X, self.points)\n",
    "            \n",
    "            weights_of_points = np.ones(P.shape)\n",
    "            if self.weights == 'distance':\n",
    "                weights_of_points = 'your code'\n",
    "                \n",
    "            # <your code>\n",
    "            pass\n",
    "        \n",
    "        else: \n",
    "            raise NotFittedError(\"CustomKNeighborsClassifier instance is not fitted yet\")\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomKNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.get_pairwise_distances(np.array([[0  , 1]  , [1, 1]]), \n",
    "                                                np.array([[0.5, 0.5], [1, 0]])),\n",
    "                   np.array([[0.70710678, 1.41421356],\n",
    "                             [0.70710678, 1.        ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_ = ['one', 'two', 'three']\n",
    "assert np.allclose(model.get_class_weights(np.array(['one', 'one', 'three', 'two']), np.array([1, 1, 0, 4])), \n",
    "                   np.array([2,4,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "knn.fit(X_train, list(map(str, y_train)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.predict_proba(X_test), knn.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc == 1\n",
    "assert test_acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Take a look at the confusion matrix and tell what numbers the model confuses and why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different n_neighbors parameters and compare the output probabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare both 'uniform' and 'distance' weights and share your thoughts in what situations which parameter can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest another distance measurement function that could improve the quality of the classification for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest different task and distance function that you think would be suitable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Synthetic Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/tabular-playground-series-apr-2021/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "PassengerId                                                                  \n",
       "0                   1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1                   0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2                   0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3                   0       3     Kramer, James  male  19.00      0      0   \n",
       "4                   1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "                Ticket   Fare   Cabin Embarked  \n",
       "PassengerId                                     \n",
       "0               209245  27.14  C12239        S  \n",
       "1                27323  13.35     NaN        S  \n",
       "2            CA 457703  71.29     NaN        S  \n",
       "3             A. 10866  13.04     NaN        S  \n",
       "4               427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      56114\n",
       "female    43886\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Sex between male and female')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Sex', data=data)\n",
    "plt.title('Distribution of Sex between male and female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisely, 56.114% were male and 43.886% were female\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precisely, {100*data.Sex.value_counts()[0]/len(data)}% were male and {100*data.Sex.value_counts()[1]/len(data)}% were female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n",
    "\n",
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model, load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "\n",
    "**Note**. X points will depend on your kaggle public leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.79 \\leq score < 0.80,$$\n",
    "$$ f(score) = 2.5, \\ \\ 0.80 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 4.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
