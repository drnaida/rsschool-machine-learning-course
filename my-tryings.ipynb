{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea84d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff956e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_normalization = ['Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "columns_for_bins = ['Elevation', 'Horizontal_Distance_To_Roadways']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ab6d1",
   "metadata": {},
   "source": [
    "**_Get data_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980bfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4d65f",
   "metadata": {},
   "source": [
    "**_Get training data_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ea2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"Cover_Type\", axis=1)\n",
    "y = dataset[\"Cover_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3fa83e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68759be",
   "metadata": {},
   "source": [
    "**_Get test data_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58eac8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "id_column = test_data[\"Id\"].copy(deep=True)\n",
    "test_data.drop(\"Id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0461f",
   "metadata": {},
   "source": [
    "**_Normalize data_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ba2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[columns_for_normalization] = normalize(X[columns_for_normalization])\n",
    "test_data[columns_for_normalization] = normalize(test_data[columns_for_normalization])\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ct = ColumnTransformer([\n",
    "#         ('somename', StandardScaler(), columns_for_normalization)\n",
    "#     ], remainder='passthrough')\n",
    "\n",
    "# X = ct.fit_transform(X)\n",
    "# test_data = ct.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009332d",
   "metadata": {},
   "source": [
    "**_Train model_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd03e0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, random_state=42).fit(X, y)\n",
    "model.fit(X, y)\n",
    "y_predicted = model.predict(test_data)\n",
    "df_for_saving = pd.DataFrame(y_predicted, index=id_column, columns=[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd27a9",
   "metadata": {},
   "source": [
    "**_Save dataset_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074e3c7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_for_saving.to_csv('cover_type.csv', index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334ca4bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3702991729.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Combinations tried:\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Combinations tried:\n",
    "    - standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87783fce",
   "metadata": {},
   "source": [
    "1 - Spruce/Fir\n",
    "\n",
    "2 - Lodgepole Pine\n",
    "\n",
    "3 - Ponderosa Pine\n",
    "\n",
    "4 - Cottonwood/Willow\n",
    "\n",
    "5 - Aspen\n",
    "\n",
    "6 - Douglas-fir\n",
    "\n",
    "7 - Krummholz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615afdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
    "df2 = data.groupby(['Wilderness_Area1', 'Cover_Type'])['Wilderness_Area1'].count().unstack('Cover_Type')\n",
    "df2[[1, 2, 3, 4, 5, 6, 7]].plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.groupby(['Wilderness_Area2', 'Cover_Type'])['Wilderness_Area2'].count().unstack('Cover_Type')\n",
    "df2[[1, 2, 3, 4, 5, 6, 7]].plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.groupby(['Wilderness_Area3', 'Cover_Type'])['Wilderness_Area3'].count().unstack('Cover_Type')\n",
    "df2[[1, 2, 3, 4, 5, 6, 7]].plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b397cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = data.groupby(['Wilderness_Area4', 'Cover_Type'])['Wilderness_Area4'].count().unstack('Cover_Type')\n",
    "df2[[1, 2, 3, 4, 5, 6, 7]].plot(kind='bar', stacked=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
